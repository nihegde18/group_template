{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Project Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Description\n",
    "\n",
    "You will design and execute a machine learning project. There are a few constraints on the nature of the allowed project. \n",
    "- The problem addressed will not be a \"toy problem\" or \"common training students problem\" like mtcars, iris, palmer penguins etc.\n",
    "- The dataset will have >1k observations and >5 variables. I'd prefer more like >10k observations and >10 variables. A general rule is that if you have >100x more observations than variables, your solution will likely generalize a lot better. The goal of training an unsupervised machine learning model is to learn the underlying pattern in a dataset in order to generalize well to unseen data, so choosing a large dataset is very important.\n",
    "\n",
    "- The project must include some elements of unsupervised learning, but you are welcome to include some supervised or other learning approaches as well.\n",
    "- The project will include a model selection and/or feature selection component where you will be looking for the best setup to maximize the performance of your ML system.\n",
    "- You will evaluate the performance of your ML system using more than one appropriate metric\n",
    "- You will be writing a report describing and discussing these accomplishments\n",
    "\n",
    "\n",
    "Feel free to delete this description section when you hand in your proposal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "Hopefully your team is at least this good. Obviously you should replace these with your names.\n",
    "\n",
    "- Tiffany Cheng\n",
    "- Varsha Sampath\n",
    "- Nikhil Hegde"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "\n",
    "The goal of this project is to seek to understand the ever-changing nature of the United States housing market to uncover patterns in housing prices within districts over a decade. Utilizing a dataset sourced from Zillow, encompassing 895 metro areas with 294 variables spanning from January 2000 to January 2024, the goal is to develop a model that identifies clusters of districts with similar housing price trajectories. The temporal clustering approach involves data preprocessing, feature engineering, and the application of specialized clustering algorithms such as Time-Series K-Means and Dynamic Time Warping. The success of the project will be measured through the evaluation of clustering performance, considering the model's ability to discern meaningful temporal patterns, with additional emphasis on preprocessing efficiency, feature relevance, and potential contributions to long-term trend analysis in the housing market, using standard K-Means as a baseline for our evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "The United States housing market is dynamic, influenced by factors such as economic conditions, interest rates, and demographic trends. On a macro level, supply and demand play a crucial role, with limited housing inventory often driving prices higher. Economic growth, job markets, and mortgage rates impact affordability, while regional variations contribute to diverse market conditions. Additionally, government policies and regulations, including zoning laws and incentives, shape the overall landscape of the housing market. On a more micro level, differences between and even within housing districts can impact the pricing of housing. For example, research shows that, even though redlining is illegal, homes in regions with high Black populations and concentrations of people of color tend to still be undervalued significantly.<a name=\"lorenz\"></a>[<sup>[1]</sup>](#lorenznote)\n",
    "Much of the current research that exists uses supervised machine learning methods to predict housing prices, such as a 2020 paper which used random forest classification to achieve this.<a name=\"admonish\"></a>[<sup>[2]</sup>](#admonishnote) However, doing so does not provide very much regional information about the districts themselves.\n",
    "Creating a model that is able to identify clusters of housing areas that demonstrate similar trends may reveal useful information not only for investors and homeowners but also for social workers and urban planners who may want to study how social factors like race, education, and social class might impact housing prices and affordability within regions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "In this project, we aim to uncover patterns of similarity among housing districts across the United States over a span of 10 years using temporal clustering techniques. The real estate market is dynamic, with district-level housing prices influenced by a myriad of factors including economic conditions, demographics , and government policy. Traditional static analysis methods fall short in capturing the temporal evolution of housing market behaviors. Therefore, our objective is to develop a machine learning model that can identify clusters of districts with similar housing price trajectories over time. This approach will provide valuable insights for investors, policymakers, and researchers interested in understanding the long-term trends and cyclical behaviors of the housing market on a district level.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "### Dataset Information\n",
    "Link/Reference to Obtain It: https://www.zillow.com/research/data/ The dataset can be accessed and downloaded from Zillow's research data page, specifically the section for metro-level housing values. Direct URL access might vary, but it is generally found under the Zillow Research Data page.\n",
    "\n",
    "Description of the Size of the Dataset:\n",
    "\n",
    "Number of Observations (Rows): 895, each representing a different metro area in the United States.\n",
    "Number of Variables (Columns): 294, including identifiers, geographic names, and monthly housing value estimates from January 2000 to January 2024.\n",
    "What an Observation Consists Of:\n",
    "\n",
    "Identifiers: RegionID (unique ID for each metro area),\n",
    "SizeRank (a rank based on the size or importance of the metro area).\n",
    "Geographic Names: RegionName (name of the metro area), StateName (name of the state for the metro area, if applicable).\n",
    "Temporal Data: Monthly housing value estimates starting from January 2000 to January 2024, represented as separate columns for each month.\n",
    "Critical Variables and How They Are Represented:\n",
    "\n",
    "Temporal Housing Values: Columns from 2000-01-31 to 2024-01-31, represented as floating-point numbers, indicating the estimated housing values for each metro area per month.\n",
    "Geographic Identifiers: RegionName and RegionID, which are crucial for linking housing data to specific metro areas.\n",
    "Special Handling, Transformations, Cleaning, etc., Needed:\n",
    "\n",
    "Aggregation: Monthly data will need to be aggregated into yearly averages to focus on long-term trends and reduce the impact of short-term fluctuations.\n",
    "Missing Data Handling: Identify and address missing values, especially in housing value estimates, possibly through imputation or exclusion of incomplete records.\n",
    "Normalization: Housing values might need to be normalized to account for differences in housing markets across regions and time, ensuring comparability.\n",
    "Spatial Encoding: Additional processing to integrate spatial information (e.g., converting RegionName or StateName to latitude and longitude) for clustering based on geographic proximity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "Benchmark Model\n",
    "As a benchmark, we can potentially use standard K-Means clustering applied directly to the annualized data without considering the temporal aspect. \n",
    "\n",
    "Solution Overview\n",
    "The core of our proposed solution involves three main steps: data preprocessing, feature engineering, and temporal clustering.\n",
    "\n",
    "Data Preprocessing:\n",
    "\n",
    "Aggregation: We will aggregate monthly housing prices into annual averages to reduce noise and focus on long-term trends.\n",
    "Normalization: Apply Min-Max Scaling or Z-Score normalization to housing prices to ensure comparability across different regions.\n",
    "Missing Value Handling: Impute missing values using techniques such as interpolation or carrying forward the last known value, depending on the nature of the gap.\n",
    "Feature Engineering:\n",
    "\n",
    "Construct a feature matrix where each row represents a district, and columns correspond to annual average housing prices and potentially other relevant features (e.g., demographic data if available).\n",
    "Incorporate spatial information by encoding geographic coordinates or using spatial autocorrelation techniques to capture the influence of location on housing prices.\n",
    "\n",
    "\n",
    "Temporal Clustering:\n",
    "\n",
    "Apply clustering algorithms designed to handle temporal data, such as Time-Series K-Means, Dynamic Time Warping (DTW), or clustering based on Long Short-Term Memory (LSTM) network embeddings, to group districts with similar housing price trajectories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "One evaluation metric we can use is a sillouette score to test how well defined the clusters of our data are. We can use this score with our models in comparison to a baseline standard K-Means model to determine whether or not our model has improved its performance. It ranges from -1 to 1, where a high score indicates well-separated clusters.\n",
    "\n",
    "Cluster Separation: A Silhouette Score close to 1 suggests that the districts within each cluster are well-matched, and the clusters are distinct.\n",
    "\n",
    "Inter-Cluster Distance: A higher score indicates that the clusters are far apart, implying clear separation and better-defined patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some ethics and privacy issues that are raised include data privacy and security, as well as its potential effects on influencing property values. Since the data primarily concerns housing prices, this can reveal sensitive information about homeowners, including their financial status. Furthermore, ensuring the security of this data against unauthorized access or cyberattacks is essential to protect the privacy of the individuals involved. Publicizing clusters of districts based on housing price trajectories might influence public perceptions and, consequently, the real estate market itself, potentially leading to speculative investments or disinvestment in certain areas. Our machine learning model may also amplify biases in the data which can cause misleading characterizations of different housing districts. \n",
    "\n",
    "To address these concerns, we want to streamline transparency and openness in our research methodology, findings, and data usage practices. For example, we must ensure that data remains anonymous to prevent the identification of individual homeowners. We can also conduct bias audits on the machine learning models to identify and mitigate potential biases. We can focus on aggregate insights that focus on broader market trends rather than pinpointing specific districts. This can help in providing valuable insights without drawing undue attention to particular areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streamlining communication\n",
    "- Being transparent about scheduling/conflicts\n",
    "- Making sure everyone’s ideas are heard and not interrupting each other during brainstorming\n",
    "- Considering all viewpoints and maintaining an open mindset\n",
    "#### Accountability\n",
    "- Being responsible for meeting deadlines \n",
    "- Completing your own share of the work\n",
    "- Communicating if any delays are anticipated\n",
    "- Updating everyone on project status\n",
    "#### Distributing workload evenly\n",
    "- Capitalizing on each other’s strengths to optimize performance\n",
    "- Helping each other out when needed\n",
    "- Offering constructive feedback\n",
    "- Figuring out areas of improvement\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace this with something meaningful that is appropriate for your needs. It doesn't have to be something that fits this format.  It doesn't have to be set in stone... \"no battle plan survives contact with the enemy\". But you need a battle plan nonetheless, and you need to keep it updated so you understand what you are trying to accomplish, who's responsible for what, and what the expected due dates are for each item.\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 2/20  |  8 PM |  Background research on topic  | Confirm project topic, deciding on communication tools, review research findings | \n",
    "| 2/25  |  8 PM |  Finding relevant datasets | Examine data and discuss data collection methods | \n",
    "| 2/28  | 8 PM  | Data wrangling and start EDA  | Examine data preparation, finalize data being used to prepare for EDA   |\n",
    "| 3/5  | 8 PM  | Finish EDA and start analysis | Review EDA results, discuss any issues and analysis plan   |\n",
    "| 3/17  | 8 PM  | Finalize analysis| Review entire project |\n",
    "| 3/19  | Before 11:59 PM  | NA | Turn in Final Project  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "<a name=\"lorenznote\"></a>1.[^](#lorenz): JUNIA HOWELL AND ELIZABETH KORVER-GLENN. (24 Sept 2020) Race determines home values more today than it did in 1980. *Rice University Kinder Institute*. https://kinder.rice.edu/urbanedge/race-determines-home-values-more-today-it-did-1980<br> \n",
    "<a name=\"admonishnote\"></a>2.[^](#admonish): Quang Truong, Minh Nguyen, Hy Dang, Bo Mei. (2020) Housing Price Prediction via Improved Machine Learning Techniques. https://www.sciencedirect.com/science/article/pii/S1877050920316318<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
